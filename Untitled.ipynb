{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'gbk' codec can't decode byte 0x80 in position 6982: illegal multibyte sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-70b9c8b42207>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-70b9c8b42207>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreadcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cihui.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[0mre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplitwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mworddict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_and_calucatedict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-70b9c8b42207>\u001b[0m in \u001b[0;36mreadcontext\u001b[1;34m(inputpath)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# 按行读取存入列表，列表中子元素为一行文字\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'gbk' codec can't decode byte 0x80 in position 6982: illegal multibyte sequence"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "def readcontext(inputpath):\n",
    "    f=open(inputpath,'r')\n",
    "    # 按行读取存入列表，列表中子元素为一行文字\n",
    "    text=f.readlines()\n",
    "    return text\n",
    "\n",
    "def splitwords(text):\n",
    "    re=[]\n",
    "    # 将列表中的每行文字按空格拆分，去掉换行，大写转成小写\n",
    "    for i in text:\n",
    "        re.extend(str(i).strip('.\\n').lower().split(' '))\n",
    "    return re\n",
    "\n",
    "def create_and_calucatedict(re):\n",
    "    #因为是单词计数，字典比较适合\n",
    "    worddict={}\n",
    "    for i in re:\n",
    "        #每读入单词判断在字典key中是否存在，不存在创建该单词key，vulue默认=1\n",
    "        if i not in worddict:\n",
    "            worddict[i]=1\n",
    "        #读入单词在字典key存在，value+1\n",
    "        else:\n",
    "            worddict[i]+=1\n",
    "    return worddict\n",
    "\n",
    "def output_txt(outputpath,worddict):\n",
    "    #将结果输出到txt\n",
    "    f=open(outputpath,'w',encoding='utf-8')\n",
    "    string=str(worddict).lstrip(\"{'\").rstrip(\"}\").replace(',','\\n').replace(\"'\",'').replace(' ','')\n",
    "    f.write(string)\n",
    "    f.closed\n",
    "\n",
    "def output_html(worddict):\n",
    "    #将结果利用pandas输出到html\n",
    "    df = pandas.DataFrame(worddict, index=[0])\n",
    "    df_T = df.T#因为结果横向显示太长，转为转置矩阵\n",
    "    #我试了一下好像html不能转，只有excel能转，尴尬......\n",
    "    df.to_html('wordcount.html')\n",
    "\n",
    "def output_excel(worddict):\n",
    "    # 将结果利用pandas输出到excel\n",
    "    df = pandas.DataFrame(worddict, index=True)\n",
    "    df_T = df.T#因为结果横向显示太长，转为转置矩阵,\n",
    "    df_T.to_excel('wordcount.xlsx')\n",
    "\n",
    "def main():\n",
    "    text = readcontext('cihui.txt')\n",
    "    re = splitwords(text)\n",
    "    worddict = create_and_calucatedict(re)\n",
    "    output_excel(worddict)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
